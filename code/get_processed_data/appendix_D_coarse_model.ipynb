{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix D: Coarse-grained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit,minimize_scalar\n",
    "import time\n",
    "from pathlib import Path\n",
    "figures_path = Path().resolve().parent / 'figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_OU_noise_batch(n_realizations: int, n_sources: int, total_steps: int, \n",
    "                            dt_sim: float, tau_c_values: np.ndarray,\n",
    "                            amplitude_values: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates OU noise for multiple realizations at once - FULLY VECTORIZED.\n",
    "    \n",
    "    Returns:\n",
    "        noise: shape (n_realizations, n_sources, total_steps)\n",
    "    \"\"\"\n",
    "    mu = 0.0\n",
    "    \n",
    "    # Pre-compute constants for all sources\n",
    "    theta = 1.0 / tau_c_values  # shape (n_sources,)\n",
    "    sigma = amplitude_values * np.sqrt(2 * theta)  # shape (n_sources,)\n",
    "    \n",
    "    exp_minus_theta_dt = np.exp(-theta * dt_sim)  # shape (n_sources,)\n",
    "    term1_drift = mu * (1 - exp_minus_theta_dt)  # shape (n_sources,)\n",
    "    variance = (sigma**2 * (1 - np.exp(-2 * theta * dt_sim))) / (2 * theta)\n",
    "    term2_stochastic_std_dev = np.sqrt(variance)  # shape (n_sources,)\n",
    "    \n",
    "    # Initialize all paths at once: (n_realizations, n_sources)\n",
    "    x = np.random.randn(n_realizations, n_sources) * amplitude_values[np.newaxis, :]\n",
    "    \n",
    "    # Allocate output: (n_realizations, n_sources, total_steps)\n",
    "    noise = np.zeros((n_realizations, n_sources, total_steps))\n",
    "    \n",
    "    # Vectorized evolution over time\n",
    "    for t in range(total_steps):\n",
    "        # Generate random increments for all realizations and sources at once\n",
    "        dW = np.random.randn(n_realizations, n_sources) * term2_stochastic_std_dev[np.newaxis, :]\n",
    "        \n",
    "        # Update: vectorized over realizations and sources\n",
    "        x = x * exp_minus_theta_dt[np.newaxis, :] + term1_drift[np.newaxis, :] + dW\n",
    "        \n",
    "        # Store\n",
    "        noise[:, :, t] = x\n",
    "    \n",
    "    return noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_continuous_phase_evolution_vectorized(noise_batch: np.ndarray,\n",
    "                                              x_trajectory: np.ndarray,\n",
    "                                              x_sources: np.ndarray,\n",
    "                                              xc: float,\n",
    "                                              dt_sim: float,\n",
    "                                              steps_per_period: int) -> tuple:\n",
    "    \"\"\"\n",
    "    Vectorized phase evolution for continuous shuttling over ALL realizations.\n",
    "    \n",
    "    Args:\n",
    "        noise_batch: shape (n_realizations, n_sources, total_steps)\n",
    "        x_trajectory: shape (steps_per_period,) - position at each step\n",
    "        x_sources: shape (n_sources,)\n",
    "        xc: correlation length\n",
    "        dt_sim: time step\n",
    "        steps_per_period: steps in one period\n",
    "    \n",
    "    Returns:\n",
    "        times: array of times (one per period)\n",
    "        W_values: shape (n_realizations, n_periods) - return probability for each realization\n",
    "    \"\"\"\n",
    "    n_realizations, n_sources, total_steps = noise_batch.shape\n",
    "    n_periods = total_steps // steps_per_period\n",
    "    \n",
    "    # Pre-compute coupling matrix: shape (steps_per_period, n_sources)\n",
    "    # For each position in trajectory, compute coupling to each source\n",
    "    coupling_matrix = np.exp(-np.abs(x_trajectory[:, np.newaxis] - x_sources[np.newaxis, :]) / xc)\n",
    "    \n",
    "    # Reshape noise to (n_realizations, n_sources, n_periods, steps_per_period)\n",
    "    noise_reshaped = noise_batch[:, :, :n_periods * steps_per_period].reshape(\n",
    "        n_realizations, n_sources, n_periods, steps_per_period)\n",
    "    \n",
    "    # Compute total noise at qubit position for each realization and time step\n",
    "    # coupling_matrix: (steps_per_period, n_sources) -> 'ab'\n",
    "    # noise_reshaped: (n_realizations, n_sources, n_periods, steps_per_period) -> 'rbra'\n",
    "    # Contract b (sources), keep r, x, a where x=n_periods\n",
    "    xi_total = np.einsum('ab,rbxa->rxa', coupling_matrix, noise_reshaped)\n",
    "    \n",
    "    # Accumulate phase within each period\n",
    "    # phi[r, p, t] = cumulative sum over t within period p for realization r\n",
    "    phi_increments = xi_total * dt_sim\n",
    "    phi_within_periods = np.cumsum(phi_increments, axis=2)\n",
    "    \n",
    "    # Get phase at end of each period\n",
    "    phi_at_period_end = phi_within_periods[:, :, -1]  # shape (n_realizations, n_periods)\n",
    "    \n",
    "    # Accumulate across periods\n",
    "    phi_cumulative = np.cumsum(phi_at_period_end, axis=1)  # shape (n_realizations, n_periods)\n",
    "    \n",
    "    # Compute return probability\n",
    "    W_values = np.cos(phi_cumulative)\n",
    "    \n",
    "    # Time array\n",
    "    times = np.arange(1, n_periods + 1) * steps_per_period * dt_sim\n",
    "    \n",
    "    return times, W_values\n",
    "\n",
    "\n",
    "def run_bucket_phase_evolution_vectorized(noise_batch: np.ndarray,\n",
    "                                         bucket_path: list,\n",
    "                                         v_ni_matrix: np.ndarray,\n",
    "                                         dt_bucket: float,\n",
    "                                         dt_bucket_steps: int,\n",
    "                                         max_repetitions: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Vectorized phase evolution for bucket model over ALL realizations.\n",
    "    \n",
    "    Args:\n",
    "        noise_batch: shape (n_realizations, n_sources, total_steps)\n",
    "        bucket_path: list of bucket indices per step\n",
    "        v_ni_matrix: shape (n_sources, n_buckets) - coupling matrix\n",
    "        dt_bucket: time spent in each bucket\n",
    "        dt_bucket_steps: number of simulation steps per bucket step\n",
    "        max_repetitions: number of full periods\n",
    "    \n",
    "    Returns:\n",
    "        W_values: shape (n_realizations, max_repetitions)\n",
    "    \"\"\"\n",
    "    n_realizations, n_sources, total_steps = noise_batch.shape\n",
    "    path_length = len(bucket_path)\n",
    "    \n",
    "    # Extract coupling for each bucket in the path: shape (n_sources, path_length)\n",
    "    coupling_path = v_ni_matrix[:, bucket_path]  # (n_sources, path_length)\n",
    "    \n",
    "    # Subsample noise at bucket step times\n",
    "    # We need to sample every dt_bucket_steps\n",
    "    step_indices = np.arange(0, max_repetitions * path_length) * dt_bucket_steps\n",
    "    step_indices = step_indices[step_indices < total_steps]\n",
    "    noise_at_steps = noise_batch[:, :, step_indices]  # (n_realizations, n_sources, max_repetitions*path_length)\n",
    "    \n",
    "    # Reshape to periods: (n_realizations, n_sources, max_repetitions, path_length)\n",
    "    noise_reshaped = noise_at_steps[:, :, :max_repetitions * path_length].reshape(\n",
    "        n_realizations, n_sources, max_repetitions, path_length)\n",
    "    \n",
    "    # Apply couplings and sum over sources: (n_realizations, max_repetitions, path_length)\n",
    "    # coupling_path: (n_sources, path_length) -> 'ab'\n",
    "    # noise_reshaped: (n_realizations, n_sources, max_repetitions, path_length) -> 'raxb'\n",
    "    # Contract a (sources), keep r, x, b\n",
    "    xi_total = np.einsum('ab,raxb->rxb', coupling_path, noise_reshaped)\n",
    "    \n",
    "    # Accumulate phase within each period\n",
    "    phi_increments = xi_total * dt_bucket\n",
    "    phi_within_periods = np.sum(phi_increments, axis=2)  # shape (n_realizations, max_repetitions)\n",
    "    \n",
    "    # Accumulate across periods\n",
    "    phi_cumulative = np.cumsum(phi_within_periods, axis=1)  # shape (n_realizations, max_repetitions)\n",
    "    \n",
    "    # Compute return probability\n",
    "    W_values = np.cos(phi_cumulative)\n",
    "    \n",
    "    return W_values\n",
    "\n",
    "\n",
    "def run_stationary_bucket_evolution_vectorized(noise_batch: np.ndarray,\n",
    "                                              bucket_idx: int,\n",
    "                                              v_ni_matrix: np.ndarray,\n",
    "                                              dt_sim: float,\n",
    "                                              steps_per_period: int,\n",
    "                                              n_periods: int) -> tuple:\n",
    "    \"\"\"\n",
    "    Vectorized stationary evolution at fixed bucket over ALL realizations.\n",
    "    \n",
    "    Args:\n",
    "        noise_batch: shape (n_realizations, n_sources, total_steps)\n",
    "        bucket_idx: which bucket to stay at\n",
    "        v_ni_matrix: shape (n_sources, n_buckets)\n",
    "        dt_sim: time step\n",
    "        steps_per_period: steps per measurement period\n",
    "        n_periods: number of periods\n",
    "    \n",
    "    Returns:\n",
    "        times: array of times\n",
    "        W_values: shape (n_realizations, n_periods)\n",
    "    \"\"\"\n",
    "    n_realizations, n_sources, total_steps = noise_batch.shape\n",
    "    \n",
    "    # Get coupling for this bucket: shape (n_sources,)\n",
    "    coupling = v_ni_matrix[:, bucket_idx]\n",
    "    \n",
    "    # Limit to available steps\n",
    "    max_steps = n_periods * steps_per_period\n",
    "    noise_truncated = noise_batch[:, :, :max_steps]  # (n_realizations, n_sources, max_steps)\n",
    "    \n",
    "    # Reshape to periods: (n_realizations, n_sources, n_periods, steps_per_period)\n",
    "    noise_reshaped = noise_truncated.reshape(n_realizations, n_sources, n_periods, steps_per_period)\n",
    "    \n",
    "    # Apply coupling and sum over sources: (n_realizations, n_periods, steps_per_period)\n",
    "    # coupling: (n_sources,) -> 'a'\n",
    "    # noise_reshaped: (n_realizations, n_sources, n_periods, steps_per_period) -> 'raxb'\n",
    "    # Contract a (sources), keep r, x, b\n",
    "    xi_total = np.einsum('a,raxb->rxb', coupling, noise_reshaped)\n",
    "    \n",
    "    # Accumulate phase within each period\n",
    "    phi_increments = xi_total * dt_sim\n",
    "    phi_within_periods = np.sum(phi_increments, axis=2)  # shape (n_realizations, n_periods)\n",
    "    \n",
    "    # Accumulate across periods\n",
    "    phi_cumulative = np.cumsum(phi_within_periods, axis=1)  # shape (n_realizations, n_periods)\n",
    "    \n",
    "    # Compute return probability\n",
    "    W_values = np.cos(phi_cumulative)\n",
    "    \n",
    "    # Time array\n",
    "    times = np.arange(1, n_periods + 1) * steps_per_period * dt_sim\n",
    "    \n",
    "    return times, W_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def compute_amplitude_for_OU(T2_target: float, tau_c: float, scaling_factor: float = 1.0) -> float:\n",
    "    \"\"\"Compute noise amplitude for OU process to achieve target T2*.\"\"\"\n",
    "    return scaling_factor / np.sqrt(T2_target * tau_c)\n",
    "\n",
    "\n",
    "def compute_v_ni_matrix(x_sources: np.ndarray, x_buckets: np.ndarray, xc: float) -> np.ndarray:\n",
    "    \"\"\"Compute coupling matrix v_ni[n, i] = exp(-|x_buckets[i] - x_sources[n]| / xc).\"\"\"\n",
    "    return np.exp(-np.abs(x_sources[:, np.newaxis] - x_buckets[np.newaxis, :]) / xc)\n",
    "\n",
    "\n",
    "def compute_correlation_matrix(x_buckets: np.ndarray, xc: float) -> np.ndarray:\n",
    "    \"\"\"Compute spatial correlation matrix r_{nm} = exp(-|x_m - x_n|/xc).\"\"\"\n",
    "    return np.exp(-np.abs(x_buckets[:, np.newaxis] - x_buckets[np.newaxis, :]) / xc)\n",
    "\n",
    "\n",
    "def exp_decay_func(t: np.ndarray, T2: float, alpha: float) -> np.ndarray:\n",
    "    \"\"\"Model function: W = exp(-[t/T2]^alpha).\"\"\"\n",
    "    return np.exp(-(t / T2)**alpha)\n",
    "\n",
    "\n",
    "def fit_T2_alpha(times, W_values) -> tuple:\n",
    "    \"\"\"Fit W = exp(-[t/T2*]^alpha) to the data, using only W > 0.5.\"\"\"\n",
    "    times = np.array(times)\n",
    "    W_values = np.array(W_values)\n",
    "    \n",
    "    # Only fit the first part where W > 0.5\n",
    "    valid_mask = W_values > 0.5\n",
    "    if np.sum(valid_mask) < 3:\n",
    "        return 1.0, 2.0\n",
    "    \n",
    "    t_fit = times[valid_mask]\n",
    "    W_fit = W_values[valid_mask]\n",
    "    \n",
    "    T2_guess = t_fit[-1] / (-np.log(W_fit[-1]))**(1/2) if W_fit[-1] > 0 else 1.0\n",
    "    alpha_guess = 1.6\n",
    "    \n",
    "    try:\n",
    "        popt, _ = curve_fit(exp_decay_func, t_fit, W_fit, \n",
    "                           p0=[T2_guess, alpha_guess],\n",
    "                           bounds=([0.01, 0.5], [200, 2.4]))\n",
    "        return popt[0], popt[1]\n",
    "    except:\n",
    "        return T2_guess, alpha_guess\n",
    "\n",
    "\n",
    "def DC_model(t: float, T2_vec: np.ndarray, alpha_vec: np.ndarray, \n",
    "             r_matrix: np.ndarray, M: int) -> float:\n",
    "    \"\"\"DC model prediction.\"\"\"\n",
    "    terms = (t / (M * T2_vec))**alpha_vec\n",
    "    chi = np.sum(r_matrix * np.sqrt(terms[:, np.newaxis] * terms[np.newaxis, :]))\n",
    "    return np.exp(-chi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast Phase-Based Benchmark Configuration:\n",
      "  N_CONFIGURATIONS = 10\n",
      "  N_REALIZATIONS per config = 50\n",
      "  MAX_REPETITIONS = 120\n",
      "  DT_SIM = 0.002\n",
      "  STEPS_PER_PERIOD = 500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "N_CONFIGURATIONS = 100\n",
    "N_REALIZATIONS = 50\n",
    "\n",
    "# Physical parameters\n",
    "DISTANCE = 1.0  # Normalized distance\n",
    "DISTANCE_NM = 200.0  # Physical distance in nanometers\n",
    "PERIOD = 1.0\n",
    "PERIOD_PHYSICAL = 0.04  # µs\n",
    "\n",
    "# Noise parameters\n",
    "T2_RANGE_US = (1, 10.0)\n",
    "T2_RANGE_PERIODS = (T2_RANGE_US[0] / PERIOD_PHYSICAL, T2_RANGE_US[1] / PERIOD_PHYSICAL)\n",
    "OM_MIN = 1/10000\n",
    "OM_MAX = 1/5\n",
    "XC_RANGE = (0.2, 0.8)\n",
    "\n",
    "# Geometry\n",
    "N_BUCKETS = 10\n",
    "N_SOURCES = 20\n",
    "\n",
    "# Time parameters\n",
    "MAX_REPETITIONS = 120\n",
    "STEPS_PER_BUCKET_STEP = 25\n",
    "DT_BUCKET = PERIOD / (2.0 * N_BUCKETS)\n",
    "DT_SIM = DT_BUCKET / STEPS_PER_BUCKET_STEP\n",
    "STEPS_PER_PERIOD = int(PERIOD / DT_SIM)\n",
    "TOTAL_STEPS = STEPS_PER_PERIOD * MAX_REPETITIONS\n",
    "\n",
    "print(f\"Fast Phase-Based Benchmark Configuration:\")\n",
    "print(f\"  N_CONFIGURATIONS = {N_CONFIGURATIONS}\")\n",
    "print(f\"  N_REALIZATIONS per config = {N_REALIZATIONS}\")\n",
    "print(f\"  MAX_REPETITIONS = {MAX_REPETITIONS}\")\n",
    "print(f\"  DT_SIM = {DT_SIM}\")\n",
    "print(f\"  STEPS_PER_PERIOD = {STEPS_PER_PERIOD}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geometry:\n",
      "  Buckets: 10 from -0.500 to 0.500\n",
      "  Sources: 20\n",
      "  Bucket path length: 20 steps/period\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "x_sources = np.linspace(-DISTANCE / 1.5, DISTANCE / 1.5, N_SOURCES)\n",
    "x_sources += np.random.uniform(-DISTANCE / N_SOURCES, DISTANCE / N_SOURCES, N_SOURCES)\n",
    "x_buckets = np.linspace(-DISTANCE / 2.0, DISTANCE / 2.0, N_BUCKETS)\n",
    "bucket_path = list(range(N_BUCKETS)) + list(range(N_BUCKETS - 1, -1, -1))\n",
    "\n",
    "# Pre-compute trajectory for continuous model\n",
    "w0 = 2.0 * np.pi / PERIOD\n",
    "t_trajectory = np.linspace(0, PERIOD, STEPS_PER_PERIOD, endpoint=False)\n",
    "x_trajectory = -DISTANCE / 2.0 * np.cos(w0 * t_trajectory)\n",
    "\n",
    "print(f\"Geometry:\")\n",
    "print(f\"  Buckets: {N_BUCKETS} from {x_buckets[0]:.3f} to {x_buckets[-1]:.3f}\")\n",
    "print(f\"  Sources: {N_SOURCES}\")\n",
    "print(f\"  Bucket path length: {len(bucket_path)} steps/period\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Configuration 1/10\n",
      "============================================================\n",
      "\n",
      "  Running 50 shuttling simulations (VECTORIZED)...\n",
      "    Generated noise batch: (50, 20, 60000)\n",
      "    Continuous: T2*=5.62 µs, α=1.691\n",
      "    Bucket:     T2*=5.46 µs, α=1.691\n",
      "\n",
      "  Measuring stationary decay at 10 buckets for DC model (VECTORIZED)...\n",
      "    Bucket T2* range: 3.59 µs\n",
      "    DC Model: T2*=5.96 µs, α=1.489\n",
      "              xc_fit=0.147 (true=0.372)\n",
      "\n",
      "  Configuration complete in 7.4s\n",
      "  Overall: 1/10 (0.1 min elapsed, ~1.1 min remaining)\n",
      "\n",
      "============================================================\n",
      "Configuration 2/10\n",
      "============================================================\n",
      "\n",
      "  Running 50 shuttling simulations (VECTORIZED)...\n",
      "    Generated noise batch: (50, 20, 60000)\n",
      "    Continuous: T2*=3.53 µs, α=1.521\n",
      "    Bucket:     T2*=3.50 µs, α=1.482\n",
      "\n",
      "  Measuring stationary decay at 10 buckets for DC model (VECTORIZED)...\n",
      "    Bucket T2* range: 2.02 µs\n",
      "    DC Model: T2*=3.67 µs, α=1.447\n",
      "              xc_fit=0.089 (true=0.617)\n",
      "\n",
      "  Configuration complete in 7.1s\n",
      "  Overall: 2/10 (0.2 min elapsed, ~1.0 min remaining)\n",
      "\n",
      "============================================================\n",
      "Configuration 3/10\n",
      "============================================================\n",
      "\n",
      "  Running 50 shuttling simulations (VECTORIZED)...\n",
      "    Generated noise batch: (50, 20, 60000)\n",
      "    Continuous: T2*=2.41 µs, α=1.826\n",
      "    Bucket:     T2*=2.39 µs, α=1.840\n",
      "\n",
      "  Measuring stationary decay at 10 buckets for DC model (VECTORIZED)...\n",
      "    Bucket T2* range: 2.06 µs\n",
      "    DC Model: T2*=2.36 µs, α=1.671\n",
      "              xc_fit=0.345 (true=0.558)\n",
      "\n",
      "  Configuration complete in 12.0s\n",
      "  Overall: 3/10 (0.4 min elapsed, ~1.0 min remaining)\n",
      "\n",
      "============================================================\n",
      "Configuration 4/10\n",
      "============================================================\n",
      "\n",
      "  Running 50 shuttling simulations (VECTORIZED)...\n",
      "    Generated noise batch: (50, 20, 60000)\n",
      "    Continuous: T2*=3.46 µs, α=1.666\n",
      "    Bucket:     T2*=3.25 µs, α=1.681\n",
      "\n",
      "  Measuring stationary decay at 10 buckets for DC model (VECTORIZED)...\n",
      "    Bucket T2* range: 1.91 µs\n",
      "    DC Model: T2*=3.82 µs, α=1.685\n",
      "              xc_fit=0.138 (true=0.476)\n",
      "\n",
      "  Configuration complete in 6.9s\n",
      "  Overall: 4/10 (0.6 min elapsed, ~0.8 min remaining)\n",
      "\n",
      "============================================================\n",
      "Configuration 5/10\n",
      "============================================================\n",
      "\n",
      "  Running 50 shuttling simulations (VECTORIZED)...\n",
      "    Generated noise batch: (50, 20, 60000)\n",
      "    Continuous: T2*=2.84 µs, α=1.256\n",
      "    Bucket:     T2*=2.78 µs, α=1.235\n",
      "\n",
      "  Measuring stationary decay at 10 buckets for DC model (VECTORIZED)...\n",
      "    Bucket T2* range: 1.43 µs\n",
      "    DC Model: T2*=2.74 µs, α=1.604\n",
      "              xc_fit=0.118 (true=0.458)\n",
      "\n",
      "  Configuration complete in 6.7s\n",
      "  Overall: 5/10 (0.7 min elapsed, ~0.7 min remaining)\n",
      "\n",
      "============================================================\n",
      "Configuration 6/10\n",
      "============================================================\n",
      "\n",
      "  Running 50 shuttling simulations (VECTORIZED)...\n",
      "    Generated noise batch: (50, 20, 60000)\n",
      "    Continuous: T2*=2.37 µs, α=1.826\n",
      "    Bucket:     T2*=2.38 µs, α=1.835\n",
      "\n",
      "  Measuring stationary decay at 10 buckets for DC model (VECTORIZED)...\n",
      "    Bucket T2* range: 1.45 µs\n",
      "    DC Model: T2*=2.57 µs, α=1.799\n",
      "              xc_fit=0.231 (true=0.758)\n",
      "\n",
      "  Configuration complete in 8.2s\n",
      "  Overall: 6/10 (0.8 min elapsed, ~0.5 min remaining)\n",
      "\n",
      "============================================================\n",
      "Configuration 7/10\n",
      "============================================================\n",
      "\n",
      "  Running 50 shuttling simulations (VECTORIZED)...\n",
      "    Generated noise batch: (50, 20, 60000)\n",
      "    Continuous: T2*=5.54 µs, α=1.595\n",
      "    Bucket:     T2*=5.46 µs, α=1.625\n",
      "\n",
      "  Measuring stationary decay at 10 buckets for DC model (VECTORIZED)...\n",
      "    Bucket T2* range: 3.04 µs\n",
      "    DC Model: T2*=5.66 µs, α=1.519\n",
      "              xc_fit=0.104 (true=0.270)\n",
      "\n",
      "  Configuration complete in 6.4s\n",
      "  Overall: 7/10 (0.9 min elapsed, ~0.4 min remaining)\n",
      "\n",
      "============================================================\n",
      "Configuration 8/10\n",
      "============================================================\n",
      "\n",
      "  Running 50 shuttling simulations (VECTORIZED)...\n",
      "    Generated noise batch: (50, 20, 60000)\n",
      "    Continuous: T2*=1.13 µs, α=1.725\n",
      "    Bucket:     T2*=1.10 µs, α=1.716\n",
      "\n",
      "  Measuring stationary decay at 10 buckets for DC model (VECTORIZED)...\n",
      "    Bucket T2* range: 0.65 µs\n",
      "    DC Model: T2*=1.09 µs, α=1.753\n",
      "              xc_fit=0.253 (true=0.346)\n",
      "\n",
      "  Configuration complete in 6.7s\n",
      "  Overall: 8/10 (1.0 min elapsed, ~0.3 min remaining)\n",
      "\n",
      "============================================================\n",
      "Configuration 9/10\n",
      "============================================================\n",
      "\n",
      "  Running 50 shuttling simulations (VECTORIZED)...\n",
      "    Generated noise batch: (50, 20, 60000)\n",
      "    Continuous: T2*=2.41 µs, α=1.622\n",
      "    Bucket:     T2*=2.38 µs, α=1.611\n",
      "\n",
      "  Measuring stationary decay at 10 buckets for DC model (VECTORIZED)...\n",
      "    Bucket T2* range: 1.55 µs\n",
      "    DC Model: T2*=2.45 µs, α=1.279\n",
      "              xc_fit=0.108 (true=0.679)\n",
      "\n",
      "  Configuration complete in 6.8s\n",
      "  Overall: 9/10 (1.1 min elapsed, ~0.1 min remaining)\n",
      "\n",
      "============================================================\n",
      "Configuration 10/10\n",
      "============================================================\n",
      "\n",
      "  Running 50 shuttling simulations (VECTORIZED)...\n",
      "    Generated noise batch: (50, 20, 60000)\n",
      "    Continuous: T2*=1.11 µs, α=1.919\n",
      "    Bucket:     T2*=1.08 µs, α=1.947\n",
      "\n",
      "  Measuring stationary decay at 10 buckets for DC model (VECTORIZED)...\n",
      "    Bucket T2* range: 0.79 µs\n",
      "    DC Model: T2*=1.24 µs, α=1.692\n",
      "              xc_fit=0.181 (true=0.530)\n",
      "\n",
      "  Configuration complete in 6.6s\n",
      "  Overall: 10/10 (1.2 min elapsed, ~0.0 min remaining)\n",
      "\n",
      "============================================================\n",
      "✓ VECTORIZED BENCHMARK COMPLETE!\n",
      "============================================================\n",
      "Total time: 1.2 minutes\n",
      "Average time per configuration: 7.5 seconds\n",
      "Speedup vs full density matrix: ~50-100x expected (phase-only + vectorization)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "results = {\n",
    "    'T2_continuous': [],\n",
    "    'alpha_continuous': [],\n",
    "    'T2_bucket': [],\n",
    "    'alpha_bucket': [],\n",
    "    'T2_dc': [],\n",
    "    'alpha_dc': [],\n",
    "    'T2_target': [],\n",
    "    'tau_c_mean': [],\n",
    "    'xc': [],\n",
    "    'amplitude_mean': [],\n",
    "    'xc_fitted_dc': [],\n",
    "    'T2_per_bucket': [],  # Store per-bucket T2 for all configurations\n",
    "    'alpha_per_bucket': []  # Store per-bucket alpha for all configurations\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i_config in range(N_CONFIGURATIONS):\n",
    "    config_start = time.time()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Configuration {i_config + 1}/{N_CONFIGURATIONS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Random parameters\n",
    "    T2_target = np.random.uniform(T2_RANGE_PERIODS[0], T2_RANGE_PERIODS[1])\n",
    "    xc = np.random.uniform(XC_RANGE[0], XC_RANGE[1])\n",
    "    omega_values = np.exp(np.random.uniform(np.log(OM_MIN), np.log(OM_MAX), N_SOURCES))\n",
    "    tau_c_values = 1.0 / omega_values\n",
    "    tau_c_mean = np.mean(tau_c_values)\n",
    "    amplitude_values = np.array([compute_amplitude_for_OU(T2_target, tau_c) \n",
    "                                 for tau_c in tau_c_values])\n",
    "    amplitude_mean = np.mean(amplitude_values)\n",
    "    \n",
    "    results['T2_target'].append(T2_target)\n",
    "    results['tau_c_mean'].append(tau_c_mean)\n",
    "    results['xc'].append(xc)\n",
    "    results['amplitude_mean'].append(amplitude_mean)\n",
    "    \n",
    "    v_ni = compute_v_ni_matrix(x_sources, x_buckets, xc)\n",
    "    \n",
    "    # --- Run Continuous and Bucket Models (VECTORIZED) ---\n",
    "    print(f\"\\n  Running {N_REALIZATIONS} shuttling simulations (VECTORIZED)...\")\n",
    "    \n",
    "    # Generate ALL noise realizations at once: shape (N_REALIZATIONS, N_SOURCES, TOTAL_STEPS)\n",
    "    noise_batch = generate_OU_noise_batch(N_REALIZATIONS, N_SOURCES, TOTAL_STEPS, DT_SIM,\n",
    "                                          tau_c_values, amplitude_values)\n",
    "    print(f\"    Generated noise batch: {noise_batch.shape}\")\n",
    "    \n",
    "    # Continuous model - vectorized over all realizations\n",
    "    times_cont, W_cont_all = run_continuous_phase_evolution_vectorized(\n",
    "        noise_batch, x_trajectory, x_sources, xc, DT_SIM, STEPS_PER_PERIOD)\n",
    "    # W_cont_all shape: (N_REALIZATIONS, n_periods)\n",
    "    \n",
    "    # Bucket model - vectorized over all realizations  \n",
    "    W_bucket_all = run_bucket_phase_evolution_vectorized(\n",
    "        noise_batch, bucket_path, v_ni, DT_BUCKET, int(DT_BUCKET / DT_SIM), MAX_REPETITIONS)\n",
    "    # W_bucket_all shape: (N_REALIZATIONS, MAX_REPETITIONS)\n",
    "    \n",
    "    # Average over realizations (axis=0)\n",
    "    mean_W_cont = np.mean(W_cont_all, axis=0)\n",
    "    mean_W_bucket = np.mean(W_bucket_all, axis=0)\n",
    "    avg_times = times_cont\n",
    "\n",
    "    # Fit T2 and alpha\n",
    "    T2_cont, alpha_cont = fit_T2_alpha(avg_times, mean_W_cont)\n",
    "    T2_bucket, alpha_bucket = fit_T2_alpha(avg_times, mean_W_bucket)\n",
    "  \n",
    "    \n",
    "    \n",
    "    print(f\"    Continuous: T2*={T2_cont * PERIOD_PHYSICAL:.2f} µs, α={alpha_cont:.3f}\")\n",
    "    print(f\"    Bucket:     T2*={T2_bucket * PERIOD_PHYSICAL:.2f} µs, α={alpha_bucket:.3f}\")\n",
    "    \n",
    "    results['T2_continuous'].append(T2_cont)\n",
    "    results['alpha_continuous'].append(alpha_cont)\n",
    "    results['T2_bucket'].append(T2_bucket)\n",
    "    results['alpha_bucket'].append(alpha_bucket)\n",
    "    \n",
    "    # --- DC Model: Stationary measurements (VECTORIZED) ---\n",
    "    print(f\"\\n  Measuring stationary decay at {N_BUCKETS} buckets for DC model (VECTORIZED)...\")\n",
    "    \n",
    "    T2_per_bucket = []\n",
    "    alpha_per_bucket = []\n",
    "    \n",
    "    # Generate ONE batch of noise for stationary measurements\n",
    "    noise_stat_batch = generate_OU_noise_batch(N_REALIZATIONS, N_SOURCES, TOTAL_STEPS, DT_SIM,\n",
    "                                               tau_c_values, amplitude_values)\n",
    "    \n",
    "    for bucket_idx in range(N_BUCKETS):\n",
    "        # Stationary evolution at fixed bucket - vectorized over all realizations\n",
    "        times_stat, W_stat_all = run_stationary_bucket_evolution_vectorized(\n",
    "            noise_stat_batch, bucket_idx, v_ni, DT_SIM, STEPS_PER_PERIOD, MAX_REPETITIONS)\n",
    "        # W_stat_all shape: (N_REALIZATIONS, MAX_REPETITIONS)\n",
    "        \n",
    "        # Average over realizations\n",
    "        W_stat_avg = np.mean(W_stat_all, axis=0)\n",
    "\n",
    "        # Fit for this bucket\n",
    "        T2_b, alpha_b = fit_T2_alpha(times_stat, W_stat_avg)\n",
    "\n",
    "        T2_per_bucket.append(T2_b)\n",
    "        alpha_per_bucket.append(alpha_b)\n",
    "        \n",
    "    \n",
    "    T2_per_bucket = np.array(T2_per_bucket)\n",
    "    alpha_per_bucket = np.array(alpha_per_bucket)\n",
    "    \n",
    "    # Save per-bucket data for all configurations (for visualization)\n",
    "    results['T2_per_bucket'].append(T2_per_bucket * PERIOD_PHYSICAL)  # Convert to µs\n",
    "    results['alpha_per_bucket'].append(alpha_per_bucket)\n",
    "    \n",
    "    print(f\"    Bucket T2* range: {T2_per_bucket.min() * PERIOD_PHYSICAL:.2f} µs\")\n",
    "    \n",
    "    # Fit DC model with xc\n",
    "    def objective_xc_dc(xc_test):\n",
    "        r_test = compute_correlation_matrix(x_buckets, xc_test)\n",
    "        W_DC_test = np.array([DC_model(t, T2_per_bucket, alpha_per_bucket, r_test, N_BUCKETS) \n",
    "                              for t in avg_times])\n",
    "        return np.mean((mean_W_cont - W_DC_test)**2)\n",
    "    \n",
    "    result_dc = minimize_scalar(objective_xc_dc, bounds=(0.01, 1), method='bounded')\n",
    "    xc_fitted_dc = result_dc.x\n",
    "    \n",
    "    r_matrix_dc = compute_correlation_matrix(x_buckets, xc_fitted_dc)\n",
    "    W_DC = np.array([DC_model(t, T2_per_bucket, alpha_per_bucket, r_matrix_dc, N_BUCKETS) \n",
    "                     for t in avg_times])\n",
    "    \n",
    "    T2_dc, alpha_dc = fit_T2_alpha(avg_times, W_DC)\n",
    "    \n",
    "    results['T2_dc'].append(T2_dc)\n",
    "    results['alpha_dc'].append(alpha_dc)\n",
    "    results['xc_fitted_dc'].append(xc_fitted_dc)\n",
    "    \n",
    "    print(f\"    DC Model: T2*={T2_dc * PERIOD_PHYSICAL:.2f} µs, α={alpha_dc:.3f}\")\n",
    "    print(f\"              xc_fit={xc_fitted_dc:.3f} (true={xc:.3f})\")\n",
    "    \n",
    "    config_time = time.time() - config_start\n",
    "    elapsed_total = time.time() - start_time\n",
    "    avg_time_per_config = elapsed_total / (i_config + 1)\n",
    "    remaining_configs = N_CONFIGURATIONS - (i_config + 1)\n",
    "    estimated_remaining = avg_time_per_config * remaining_configs\n",
    "    \n",
    "    print(f\"\\n  Configuration complete in {config_time:.1f}s\")\n",
    "    print(f\"  Overall: {i_config + 1}/{N_CONFIGURATIONS} ({elapsed_total/60:.1f} min elapsed, ~{estimated_remaining/60:.1f} min remaining)\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"✓ VECTORIZED BENCHMARK COMPLETE!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total time: {total_time/60:.1f} minutes\")\n",
    "print(f\"Average time per configuration: {total_time/N_CONFIGURATIONS:.1f} seconds\")\n",
    "print(f\"Speedup vs full density matrix: ~50-100x expected (phase-only + vectorization)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Save results as a JSON file, making parent directory if needed\n",
    "import os\n",
    "\n",
    "output_path = '../processed_data/fig11_12/results.json'\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(results, f, indent=2, default=lambda x: x.tolist() if hasattr(x, 'tolist') else x)\n",
    "\n",
    "\n",
    "# Also save DISTANCE_NM and PERIOD_PHYSICAL in the results.json.\n",
    "results_to_save = dict(results)  # shallow copy\n",
    "results_to_save['DISTANCE_NM'] = DISTANCE_NM\n",
    "results_to_save['PERIOD_PHYSICAL'] = PERIOD_PHYSICAL\n",
    "results_to_save['N_BUCKETS'] = N_BUCKETS\n",
    "results_to_save['N_SOURCES'] = N_SOURCES\n",
    "results_to_save['N_CONFIGURATIONS'] = N_CONFIGURATIONS\n",
    "results_to_save['N_REALIZATIONS'] = N_REALIZATIONS\n",
    "results_to_save['MAX_REPETITIONS'] = MAX_REPETITIONS\n",
    "results_to_save['STEPS_PER_PERIOD'] = STEPS_PER_PERIOD\n",
    "results_to_save['DT_SIM'] = DT_SIM\n",
    "\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(results_to_save, f, indent=2, default=lambda x: x.tolist() if hasattr(x, 'tolist') else x)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
