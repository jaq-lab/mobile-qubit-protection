{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Figure 4 Data Generation\n",
        "\n",
        "This notebook processes raw shuttling experimental data to generate processed data for Figure 4.\n",
        "\n",
        "## Process:\n",
        "1. Load raw experimental data from UUIDs\n",
        "2. Process data (extract amplitudes, fit decay curves)\n",
        "3. Save processed data for plotting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import common utilities\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Add common directory to path (works in Jupyter notebooks)\n",
        "common_path = Path().resolve().parent / 'common_scripts'\n",
        "sys.path.insert(0, str(common_path))\n",
        "\n",
        "from raw_data_loader import load_raw_data_by_uuid\n",
        "from data_processor import analyze_ramsey, analyze_echo_lowfield, exp_decay, exp_decay_nob\n",
        "from data_saver import save_figure_data\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "data_path = Path().resolve().parent / 'data'\n",
        "# Data path\n",
        "\n",
        "figure_path = Path().resolve().parent / 'figures'\n",
        "\n",
        "# Processed data path (absolute path to data_analysis/processed_data)\n",
        "processed_data_path = Path().resolve().parent / 'processed_data'\n",
        "\n",
        "# Alias for convenience\n",
        "load_by_uuid = load_raw_data_by_uuid\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Raw Data: High Field Measurements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 9 Ramsey datasets\n",
            "Loaded 10 Echo datasets\n",
            "Loaded 10 CPMG-3 datasets\n"
          ]
        }
      ],
      "source": [
        "# Load Ramsey measurements\n",
        "ramsey_uuids = [1729338584952108893, 1729339566126108893, 1729344237793108893, 1729345221575108893,\n",
        "                1729346193883108893, 1729347175505108893, 1729348213411108893, 1729349391259108893, \n",
        "                1729350751425108893]\n",
        "\n",
        "ramsey_datasets = [load_by_uuid(uuid, data_path) for uuid in ramsey_uuids]\n",
        "\n",
        "# Load Echo (CPMG N=1) measurements  \n",
        "echo_uuids = [1729352661379108893, 1729353663655108893, 1729354825558108893, 1729355882400108893,\n",
        "              1729357060736108893, 1729358250009108893, 1729359473186108893, 1729360813701108893,\n",
        "              1729362400622108893, 1729364398847108893]\n",
        "\n",
        "echo_datasets = [load_by_uuid(uuid, data_path) for uuid in echo_uuids]\n",
        "\n",
        "# Load CPMG N=3 measurements\n",
        "cpmg5_uuids = [1729385219679108893, 1729386520050108893, 1729388016259108893, 1729389395062108893,\n",
        "               1729390966230108893, 1729392586241108893, 1729394301840108893, 1729396250369108893,\n",
        "               1729398660810108893, 1729401870913108893]\n",
        "\n",
        "cpmg5_datasets = [load_by_uuid(uuid, data_path) for uuid in cpmg5_uuids]\n",
        "\n",
        "print(f\"Loaded {len(ramsey_datasets)} Ramsey datasets\")\n",
        "print(f\"Loaded {len(echo_datasets)} Echo datasets\")  \n",
        "print(f\"Loaded {len(cpmg5_datasets)} CPMG-3 datasets\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analysis parameters\n",
        "cv_time = 20.0\n",
        "ramsey_cv_stops = [2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
        "echo_cv_stops = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
        "cpmg5_cv_stops = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
        "\n",
        "# Calculate shuttling distances\n",
        "shuttle_distance_ramsey = (cv_time - np.array(ramsey_cv_stops)) * 0.06 * 180\n",
        "shuttle_distance_echo = (cv_time - np.array(echo_cv_stops)) * 0.06 * 180\n",
        "shuttle_distance_cpmg5 = (cv_time - np.array(cpmg5_cv_stops)) * 0.06 * 180\n",
        "\n",
        "fit_b = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Analyzing Ramsey (High Field) ---\n",
            "Ramsey 2ns: T=5166.76±658.49 ns, n=1.59±0.19\n",
            "Ramsey 4ns: T=6245.32±2122.95 ns, n=1.76±0.33\n",
            "Ramsey 6ns: T=5838.96±449.16 ns, n=1.58±0.16\n",
            "Ramsey 8ns: T=5131.65±252.47 ns, n=1.79±0.17\n",
            "Ramsey 10ns: T=4111.88±98.37 ns, n=1.81±0.11\n",
            "Ramsey 12ns: T=3271.01±168.04 ns, n=1.99±0.29\n",
            "Ramsey 14ns: T=3662.12±100.26 ns, n=1.97±0.15\n",
            "Ramsey 16ns: T=3953.25±90.64 ns, n=2.09±0.14\n",
            "Ramsey 18ns: T=5575.52±264.43 ns, n=1.97±0.18\n"
          ]
        }
      ],
      "source": [
        "# --- Ramsey Analysis ---\n",
        "n_pipulse_ramsey = 0\n",
        "ramsey_results = []\n",
        "print(\"--- Analyzing Ramsey (High Field) ---\")\n",
        "for nit, (cv_stop, dataset) in enumerate(zip(ramsey_cv_stops, ramsey_datasets)):\n",
        "    if dataset is None:\n",
        "        print(f\"Warning: Dataset for cv_stop={cv_stop} is None. Skipping.\")\n",
        "        ramsey_results.append(None)\n",
        "        continue\n",
        "    try:\n",
        "        A, A_err, T, T_err, n, n_err, x, y, popt = analyze_ramsey(\n",
        "            dataset, n_pipulse_ramsey, cv_time, cv_stop, fit_b=fit_b\n",
        "        )\n",
        "        ramsey_results.append({\n",
        "            'cv_stop': cv_stop, \n",
        "            'dx': shuttle_distance_ramsey[nit],\n",
        "            'Amplitude': A, 'Amplitude_err': A_err,\n",
        "            'Decay time': T, 'Decay time_err': T_err,\n",
        "            'Exponent': n, 'Exponent_err': n_err,\n",
        "            'x_data': x, 'amplitudes': y, 'fit_params': popt\n",
        "        })\n",
        "        if not np.isnan(T):\n",
        "            print(f\"Ramsey {cv_stop}ns: T={T:.2f}±{T_err:.2f} ns, n={n:.2f}±{n_err:.2f}\")\n",
        "        else:\n",
        "            print(f\"Ramsey {cv_stop}ns: Fit failed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ramsey {cv_stop}ns: Error - {e}\")\n",
        "        ramsey_results.append(None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Analyzing Echo (CPMG N=1) High Field ---\n",
            "Echo 0ns: T=11192.85±648.88 ns, n=1.56±0.12\n",
            "Echo 2ns: T=13781.04±1268.15 ns, n=1.46±0.11\n",
            "Echo 4ns: T=17710.49±4184.02 ns, n=1.63±0.22\n",
            "Echo 6ns: T=15764.93±2769.01 ns, n=1.58±0.20\n",
            "Echo 8ns: T=13083.55±1015.02 ns, n=1.93±0.19\n",
            "Echo 10ns: T=9283.51±139.70 ns, n=2.05±0.08\n",
            "Echo 12ns: T=6845.27±189.23 ns, n=1.85±0.14\n",
            "Echo 14ns: T=7152.61±128.64 ns, n=2.01±0.10\n",
            "Echo 16ns: T=7433.71±101.38 ns, n=2.63±0.13\n",
            "Echo 18ns: T=14005.88±467.56 ns, n=2.63±0.15\n"
          ]
        }
      ],
      "source": [
        "# --- Echo Analysis (CPMG N=1) ---\n",
        "n_pipulse_echo = 1\n",
        "echo_results = []\n",
        "print(\"\\n--- Analyzing Echo (CPMG N=1) High Field ---\")\n",
        "for nit, (cv_stop, dataset) in enumerate(zip(echo_cv_stops, echo_datasets)):\n",
        "    if dataset is None:\n",
        "        print(f\"Warning: Dataset for cv_stop={cv_stop} is None. Skipping.\")\n",
        "        echo_results.append(None)\n",
        "        continue\n",
        "    try:\n",
        "        A, A_err, T, T_err, n, n_err, x, y, popt = analyze_ramsey(\n",
        "            dataset, n_pipulse_echo, cv_time, cv_stop, fit_b=fit_b\n",
        "        )\n",
        "        echo_results.append({\n",
        "            'cv_stop': cv_stop, \n",
        "            'dx': shuttle_distance_echo[nit],\n",
        "            'Amplitude': A, 'Amplitude_err': A_err,\n",
        "            'Decay time': T, 'Decay time_err': T_err,\n",
        "            'Exponent': n, 'Exponent_err': n_err,\n",
        "            'x_data': x, 'amplitudes': y, 'fit_params': popt\n",
        "        })\n",
        "        if not np.isnan(T):\n",
        "            print(f\"Echo {cv_stop}ns: T={T:.2f}±{T_err:.2f} ns, n={n:.2f}±{n_err:.2f}\")\n",
        "        else:\n",
        "            print(f\"Echo {cv_stop}ns: Fit failed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Echo {cv_stop}ns: Error - {e}\")\n",
        "        echo_results.append(None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Analyzing CPMG N=3 (High Field) ---\n",
            "CPMG-3 0ns: T=15948.65±2158.92 ns, n=1.11±0.24\n",
            "CPMG-3 2ns: T=15976.40±1350.70 ns, n=1.23±0.19\n",
            "CPMG-3 4ns: T=20869.52±1021.32 ns, n=3.05±0.57\n",
            "CPMG-3 6ns: T=21192.89±1796.42 ns, n=1.58±0.21\n",
            "CPMG-3 8ns: T=17102.52±1148.04 ns, n=2.13±0.42\n",
            "CPMG-3 10ns: T=13602.48±415.72 ns, n=2.34±0.23\n",
            "CPMG-3 12ns: T=9691.31±375.25 ns, n=2.86±0.45\n",
            "CPMG-3 14ns: T=11263.92±362.13 ns, n=3.66±0.60\n",
            "CPMG-3 16ns: T=13051.25±496.81 ns, n=5.48±1.52\n",
            "CPMG-3 18ns: T=18106.67±616.78 ns, n=2.63±0.31\n"
          ]
        }
      ],
      "source": [
        "# --- CPMG N=3 Analysis ---\n",
        "n_pipulse_cpmg = 3\n",
        "cpmg5_results_list = []\n",
        "print(\"\\n--- Analyzing CPMG N=3 (High Field) ---\")\n",
        "for nit, (cv_stop, dataset) in enumerate(zip(cpmg5_cv_stops, cpmg5_datasets)):\n",
        "    if dataset is None:\n",
        "        print(f\"Warning: Dataset for cv_stop={cv_stop} is None. Skipping.\")\n",
        "        cpmg5_results_list.append(None)\n",
        "        continue\n",
        "    try:\n",
        "        A, A_err, T, T_err, n, n_err, x, y, popt = analyze_ramsey(\n",
        "            dataset, n_pipulse_cpmg, cv_time, cv_stop, fit_b=fit_b\n",
        "        )\n",
        "        cpmg5_results_list.append({\n",
        "            'cv_stop': cv_stop,\n",
        "            'dx': shuttle_distance_cpmg5[nit],\n",
        "            'Amplitude': A, 'Amplitude_err': A_err,\n",
        "            'Decay time': T, 'Decay time_err': T_err,\n",
        "            'Exponent': n, 'Exponent_err': n_err,\n",
        "            'x_data': x, 'amplitudes': y, 'fit_params': popt\n",
        "        })\n",
        "        if not np.isnan(T):\n",
        "            print(f\"CPMG-3 {cv_stop}ns: T={T:.2f}±{T_err:.2f} ns, n={n:.2f}±{n_err:.2f}\")\n",
        "        else:\n",
        "            print(f\"CPMG-3 {cv_stop}ns: Fit failed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"CPMG-3 {cv_stop}ns: Error - {e}\")\n",
        "        cpmg5_results_list.append(None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved figure data to ../processed_data/fig21_22/data_high.json\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Prepare the data for saving\n",
        "data_to_save = {\n",
        "    \"ramsey_results\": ramsey_results,\n",
        "    \"echo_results\": echo_results,\n",
        "    \"cpmg5_results_list\": cpmg5_results_list,\n",
        "    \"shuttle_distance_ramsey\": list(shuttle_distance_ramsey) if 'shuttle_distance_ramsey' in locals() else [],\n",
        "    \"shuttle_distance_echo\": list(shuttle_distance_echo) if 'shuttle_distance_echo' in locals() else [],\n",
        "    \"shuttle_distance_cpmg5\": list(shuttle_distance_cpmg5) if 'shuttle_distance_cpmg5' in locals() else [],\n",
        "    \"ramsey_cv_stops\": list(ramsey_cv_stops) if 'ramsey_cv_stops' in locals() else [],\n",
        "    \"echo_cv_stops\": list(echo_cv_stops) if 'echo_cv_stops' in locals() else [],\n",
        "    \"cpmg5_cv_stops\": list(cpmg5_cv_stops) if 'cpmg5_cv_stops' in locals() else [],\n",
        "    \"n_pipulse_cpmg\": n_pipulse_cpmg,\n",
        "}\n",
        "\n",
        "def make_json_safe(obj):\n",
        "    if isinstance(obj, dict):\n",
        "        return {k: make_json_safe(v) for k, v in obj.items()}\n",
        "    elif isinstance(obj, (list, tuple)):\n",
        "        return [make_json_safe(v) for v in obj]\n",
        "    elif hasattr(obj, \"tolist\"):\n",
        "        # numpy arrays\n",
        "        return obj.tolist()\n",
        "    elif isinstance(obj, float):\n",
        "        # Handle NaN, inf, -inf for JSON\n",
        "        if obj != obj:  # NaN\n",
        "            return None\n",
        "        if obj == float(\"inf\") or obj == float(\"-inf\"):\n",
        "            return None\n",
        "        return obj\n",
        "    else:\n",
        "        return obj\n",
        "\n",
        "save_path = \"../processed_data/fig21_22/data_high.json\"\n",
        "save_dir = os.path.dirname(save_path)\n",
        "if save_dir and not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "with open(save_path, \"w\") as f:\n",
        "    json.dump(make_json_safe(data_to_save), f, indent=2)\n",
        "print(f\"Saved figure data to {save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Saved fig4 data to /Users/krzywdaja/Documents/spatial-correlations-conveyor/data_analysis/protection_code_repo/processed_data/fig4/shuttling_high.pkl\n",
            "  Metadata saved to /Users/krzywdaja/Documents/spatial-correlations-conveyor/data_analysis/protection_code_repo/processed_data/fig4/shuttling_high.json\n",
            "\n",
            "Saved high field data to: /Users/krzywdaja/Documents/spatial-correlations-conveyor/data_analysis/protection_code_repo/processed_data/fig4/shuttling_high.pkl\n"
          ]
        }
      ],
      "source": [
        "# Save high field results\n",
        "shuttling_results_high = {\n",
        "    \"Ramsey\": [r for r in ramsey_results if r is not None],\n",
        "    \"Echo\": [r for r in echo_results if r is not None],\n",
        "    \"CPMG-3\": [r for r in cpmg5_results_list if r is not None]\n",
        "}\n",
        "\n",
        "metadata_high = {\n",
        "    \"cv_time\": cv_time,\n",
        "    \"field\": \"high\",\n",
        "    \"ramsey_cv_stops\": ramsey_cv_stops,\n",
        "    \"echo_cv_stops\": echo_cv_stops,\n",
        "    \"cpmg5_cv_stops\": cpmg5_cv_stops,\n",
        "    \"processing_date\": str(np.datetime64('today'))\n",
        "}\n",
        "\n",
        "save_path_high = save_figure_data(\n",
        "    shuttling_results_high,\n",
        "    figure_number=\"fig4\",\n",
        "    filename=\"shuttling_high\",\n",
        "    metadata=metadata_high,\n",
        "    base_path=str(processed_data_path)\n",
        ")\n",
        "\n",
        "print(f\"\\nSaved high field data to: {save_path_high}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Raw Data: Low Field Measurements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 10 Ramsey low field datasets\n",
            "Loaded 10 Echo low field datasets\n"
          ]
        }
      ],
      "source": [
        "# Load Ramsey measurements at low field\n",
        "ramsey_lowfield_uuids = [1730940202072108893, 1730941343072108893, 1730942584475108893, 1730943887312108893,\n",
        "                         1730945170404108893, 1730946652994108893, 1730948306204108893, 1730950465416108893,\n",
        "                         1730953832558108893, 1730960802231108893]\n",
        "\n",
        "ramsey_lowfield_datasets = [load_by_uuid(uuid, data_path) for uuid in ramsey_lowfield_uuids]\n",
        "\n",
        "# Load Echo measurements at low field\n",
        "echo_lowfield_uuids = [1731109791402108893, 1731110194512108893, 1731157390362108893, 1731111008523108893,\n",
        "                       1731111405100108893, 1731111798080108893, 1731112213009108893, 1731123163848108893,\n",
        "                       1731113018316108893, 1731124498180108893]\n",
        "\n",
        "echo_lowfield_datasets_list = [load_by_uuid(uuid, data_path) for uuid in echo_lowfield_uuids]\n",
        "\n",
        "# Organize echo lowfield datasets by cv_stop\n",
        "echo_lowfield_cv_stops = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
        "echo_lowfield_datasets = dict(zip(echo_lowfield_cv_stops, echo_lowfield_datasets_list))\n",
        "\n",
        "cv_stops_lowfield = [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
        "ramsey_lowfield_datasets_filtered = ramsey_lowfield_datasets\n",
        "print(f\"Loaded {len(ramsey_lowfield_datasets_filtered)} Ramsey low field datasets\")\n",
        "print(f\"Loaded {len(echo_lowfield_datasets)} Echo low field datasets\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Analyzing Ramsey (Low Field) ---\n",
            "Ramsey low field 0ns: T=9182.66±1167.36 ns, n=1.00±0.28\n",
            "Ramsey low field 2ns: T=11511.98±961.38 ns, n=1.90±0.61\n",
            "Ramsey low field 4ns: T=11240.15±447.49 ns, n=2.00±0.32\n",
            "Ramsey low field 6ns: T=10729.67±301.63 ns, n=1.72±0.18\n",
            "Ramsey low field 8ns: T=10015.98±318.05 ns, n=1.97±0.24\n",
            "Ramsey low field 10ns: T=8696.41±291.05 ns, n=1.74±0.19\n",
            "Ramsey low field 12ns: T=6934.09±365.43 ns, n=1.35±0.15\n",
            "Ramsey low field 14ns: T=6252.04±241.93 ns, n=1.50±0.13\n",
            "Ramsey low field 16ns: T=6338.41±319.54 ns, n=1.38±0.14\n",
            "Ramsey low field 18ns: T=7741.34±434.60 ns, n=1.30±0.17\n"
          ]
        }
      ],
      "source": [
        "n_pipulse = 0\n",
        "cv_time = 20\n",
        "cv_stop = 2\n",
        "n_pipulse_ramsey = 0\n",
        "results_lowfield = []\n",
        "print(\"--- Analyzing Ramsey (Low Field) ---\")\n",
        "shuttle_distance_ramsey_low = (cv_time - np.array(cv_stops_lowfield)) * 0.06 * 180\n",
        "\n",
        "for nit, (cv_stop, dataset) in enumerate(zip(cv_stops_lowfield, ramsey_lowfield_datasets_filtered)):\n",
        "    if dataset is None:\n",
        "        print(f\"Warning: Dataset for cv_stop={cv_stop} is None. Skipping.\")\n",
        "        results_lowfield.append(None)\n",
        "        continue\n",
        "    try:\n",
        "        A, A_err, T, T_err, n, n_err, x, y, popt = analyze_ramsey(\n",
        "            dataset, n_pipulse_ramsey, cv_time, cv_stop, measurement=\"m1_3\", fit_b=False\n",
        "        )\n",
        "        results_lowfield.append({\n",
        "            'cv_stop': cv_stop,\n",
        "            'dx': shuttle_distance_ramsey_low[nit],\n",
        "            'Amplitude': A, 'Amplitude_err': A_err,\n",
        "            'Decay time': T, 'Decay time_err': T_err,\n",
        "            'Exponent': n, 'Exponent_err': n_err,\n",
        "            'x_data': x, 'amplitudes': y, 'fit_params': popt\n",
        "        })\n",
        "        if not np.isnan(T):\n",
        "            print(f\"Ramsey low field {cv_stop}ns: T={T:.2f}±{T_err:.2f} ns, n={n:.2f}±{n_err:.2f}\")\n",
        "        else:\n",
        "            print(f\"Ramsey low field {cv_stop}ns: Fit failed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Ramsey low field {cv_stop}ns: Error - {e}\")\n",
        "        results_lowfield.append(None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Analyzing Echo (Low Field) ---\n",
            "Echo low field 0ns: T=31718.90±2362.08 ns, n=1.30±0.28\n",
            "Echo low field 2ns: T=23976.85±1393.42 ns, n=1.94±0.44\n",
            "Echo low field 4ns: T=25454.44±714.26 ns, n=2.38±0.28\n",
            "Echo low field 6ns: T=25351.93±5204.61 ns, n=4.00±2.42\n",
            "Echo low field 8ns: T=23676.93±2679.28 ns, n=1.13±0.29\n",
            "Echo low field 10ns: T=17596.64±1722.84 ns, n=1.10±0.28\n",
            "Echo low field 12ns: T=8366.29±480.90 ns, n=1.83±0.36\n",
            "Echo low field 14ns: T=9805.90±530.07 ns, n=1.44±0.21\n",
            "Echo low field 16ns: T=6587.91±379.72 ns, n=3.14±0.62\n",
            "Echo low field 18ns: T=8942.48±546.41 ns, n=1.89±0.34\n"
          ]
        }
      ],
      "source": [
        "# Process Echo low field\n",
        "results_lowfield_echo = []\n",
        "print(\"\\n--- Analyzing Echo (Low Field) ---\")\n",
        "shuttle_distance_echo_low = (cv_time - np.array(echo_lowfield_cv_stops)) * 0.06 * 180\n",
        "\n",
        "for cv_stop, dataset in echo_lowfield_datasets.items():\n",
        "    if dataset is None:\n",
        "        print(f\"Warning: Dataset for cv_stop={cv_stop} is None. Skipping.\")\n",
        "        continue\n",
        "    try:\n",
        "        result = analyze_echo_lowfield(dataset, cv_stop, cv_time)\n",
        "        if result is not None:\n",
        "            A, A_err, T, T_err, n, n_err, time_points, amplitudes, popt = result\n",
        "            idx = echo_lowfield_cv_stops.index(cv_stop)\n",
        "            results_lowfield_echo.append({\n",
        "                'cv_stop': cv_stop,\n",
        "                'dx': shuttle_distance_echo_low[idx],\n",
        "                'Amplitude': A,\n",
        "                'Amplitude_err': A_err,\n",
        "                'Decay time': T,\n",
        "                'Decay time_err': T_err,\n",
        "                'Exponent': n,\n",
        "                'Exponent_err': n_err,\n",
        "                'x_data': time_points,\n",
        "                'amplitudes': amplitudes,\n",
        "                'fit_params': popt\n",
        "            })\n",
        "            print(f\"Echo low field {cv_stop}ns: T={T:.2f}±{T_err:.2f} ns, n={n:.2f}±{n_err:.2f}\")\n",
        "        else:\n",
        "            print(f\"Echo low field {cv_stop}ns: Fit failed.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Echo low field {cv_stop}ns: Error - {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# Prepare a dictionary to hold the required data for the plot\n",
        "data_to_save = {\n",
        "    \"ramsey\": [],\n",
        "    \"echo\": []\n",
        "}\n",
        "\n",
        "# Save Ramsey (low field) data\n",
        "for r in results_lowfield:\n",
        "    # Safely cast as float for JSON serialization\n",
        "    data_to_save[\"ramsey\"].append({\n",
        "        \"cv_stop\": float(r['cv_stop']),\n",
        "        \"dx\": float(r['dx']),\n",
        "        \"Amplitude\": float(r['Amplitude']),\n",
        "        \"Amplitude_err\": float(r['Amplitude_err']),\n",
        "        \"Decay time\": float(r['Decay time']),\n",
        "        \"Decay time_err\": float(r['Decay time_err']),\n",
        "        \"Exponent\": float(r['Exponent']),\n",
        "        \"Exponent_err\": float(r['Exponent_err']),\n",
        "        \"x_data\": [float(x) for x in r['x_data']],\n",
        "        \"amplitudes\": [float(a) for a in r['amplitudes']],\n",
        "        \"fit_params\": [float(p) for p in r['fit_params']] if r['fit_params'] is not None else None,\n",
        "    })\n",
        "\n",
        "# Save Echo (low field) data\n",
        "for e in results_lowfield_echo:\n",
        "    data_to_save[\"echo\"].append({\n",
        "        \"cv_stop\": float(e['cv_stop']),\n",
        "        \"dx\": float(e['dx']),\n",
        "        \"Amplitude\": float(e['Amplitude']),\n",
        "        \"Amplitude_err\": float(e['Amplitude_err']),\n",
        "        \"Decay time\": float(e['Decay time']),\n",
        "        \"Decay time_err\": float(e['Decay time_err']),\n",
        "        \"Exponent\": float(e['Exponent']),\n",
        "        \"Exponent_err\": float(e['Exponent_err']),\n",
        "        \"x_data\": [float(x) for x in e['x_data']],\n",
        "        \"amplitudes\": [float(a) for a in e['amplitudes']],\n",
        "        \"fit_params\": [float(p) for p in e['fit_params']] if e['fit_params'] is not None else None,\n",
        "    })\n",
        "\n",
        "# Ensure the output directory exists\n",
        "output_dir = \"../processed_data/fig21_22\"\n",
        "output_path = os.path.join(output_dir, \"data_low.json\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Write out to JSON\n",
        "with open(output_path, \"w\") as f_json:\n",
        "    json.dump(data_to_save, f_json, indent=2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Saved fig4 data to /Users/krzywdaja/Documents/spatial-correlations-conveyor/data_analysis/protection_code_repo/processed_data/fig4/shuttling_low.pkl\n",
            "  Metadata saved to /Users/krzywdaja/Documents/spatial-correlations-conveyor/data_analysis/protection_code_repo/processed_data/fig4/shuttling_low.json\n",
            "\n",
            "Saved low field data to: /Users/krzywdaja/Documents/spatial-correlations-conveyor/data_analysis/protection_code_repo/processed_data/fig4/shuttling_low.pkl\n",
            "\n",
            "Data generation complete!\n"
          ]
        }
      ],
      "source": [
        "# Save low field results\n",
        "shuttling_results_low = {\n",
        "    \"Ramsey\": [r for r in results_lowfield if r is not None],\n",
        "    \"Echo\": [r for r in results_lowfield_echo if r is not None]\n",
        "}\n",
        "\n",
        "metadata_low = {\n",
        "    \"cv_time\": cv_time,\n",
        "    \"field\": \"low\",\n",
        "    \"ramsey_cv_stops\": cv_stops_lowfield,\n",
        "    \"echo_cv_stops\": echo_lowfield_cv_stops,\n",
        "    \"processing_date\": str(np.datetime64('today'))\n",
        "}\n",
        "\n",
        "save_path_low = save_figure_data(\n",
        "    shuttling_results_low,\n",
        "    figure_number=\"fig4\",\n",
        "    filename=\"shuttling_low\",\n",
        "    metadata=metadata_low,\n",
        "    base_path=str(processed_data_path)\n",
        ")\n",
        "\n",
        "print(f\"\\nSaved low field data to: {save_path_low}\")\n",
        "print(\"\\nData generation complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fig 4 data: effective model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Saved spatial fit for high field to /Users/krzywdaja/Documents/spatial-correlations-conveyor/data_analysis/protection_code_repo/processed_data/fig4/spatial_fit_high.pkl\n",
            "✓ Saved spatial fit for low field to /Users/krzywdaja/Documents/spatial-correlations-conveyor/data_analysis/protection_code_repo/processed_data/fig4/spatial_fit_low.pkl\n",
            "\n",
            "Spatial correlation fit complete!\n"
          ]
        }
      ],
      "source": [
        "# Spatial correlation fit: Calculate fitted T2 and alpha vs distance\n",
        "import pickle\n",
        "import correlation_fun\n",
        "\n",
        "# Helper function for correlation matrix\n",
        "def calculate_correlation_matrix(positions, correlation_length):\n",
        "    \"\"\"Calculate spatial correlation matrix: C_ij = exp(-|x_i - x_j|/ξ)\"\"\"\n",
        "    n = len(positions)\n",
        "    C = np.zeros((n, n))\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            C[i, j] = np.exp(-abs(positions[i] - positions[j]) / correlation_length)\n",
        "    return C\n",
        "\n",
        "# Load two-point correlation data from fig23 directory\n",
        "fig23_path = processed_data_path / 'fig23'\n",
        "for field in ['high', 'low']:\n",
        "    # Try to load the data file\n",
        "    if field == 'high':\n",
        "        filename = 'fig23_high_75mV.pkl'\n",
        "    else:\n",
        "        filename = 'fig23_low.pkl'\n",
        "    \n",
        "    filepath = fig23_path / filename\n",
        "    if not filepath.exists():\n",
        "        print(f\"Warning: Could not find {filepath}\")\n",
        "        continue\n",
        "    \n",
        "    with open(filepath, 'rb') as f:\n",
        "        two_point_data = pickle.load(f)\n",
        "    \n",
        "    # Extract chi1 data (T2 and alpha at each position)\n",
        "    if isinstance(two_point_data, list):\n",
        "        chi1_data = two_point_data\n",
        "    elif isinstance(two_point_data, dict):\n",
        "        chi1_data = two_point_data.get('chi1', two_point_data)\n",
        "    else:\n",
        "        continue\n",
        "    \n",
        "    # Extract arrays\n",
        "    x_2point = np.array([p['x'] for p in chi1_data])\n",
        "    T2_2point = np.array([p['T2'] for p in chi1_data])\n",
        "    alpha_2point = np.clip(np.array([p['n'] for p in chi1_data]), 1, 2)\n",
        "    \n",
        "    # Correlation length (dx): 120 for high, 18 for low\n",
        "    dx = 120 if field == 'high' else 18\n",
        "    \n",
        "    # Calculate fitted lines\n",
        "    T2_est, alpha_est, x_est = [], [], []\n",
        "    T2_uncorr, alpha_uncorr = [], []\n",
        "    \n",
        "    for N in range(2, min(len(x_2point), 30)):\n",
        "        if N <= len(T2_2point) and N <= len(alpha_2point):\n",
        "            # Correlated case\n",
        "            C1 = calculate_correlation_matrix(x_2point[:N+1], dx)\n",
        "            t_star, alpha_eff = correlation_fun.calculate_chi_with_background_corrected(\n",
        "                T2_2point[:N+1], alpha_2point[:N+1], N, C1, 9999999, 2)\n",
        "            T2_est.append(t_star)\n",
        "            alpha_est.append(alpha_eff)\n",
        "            x_est.append(x_2point[N-1] + (x_2point[2]-x_2point[1])/2 if N > 2 else x_2point[N-1])\n",
        "            \n",
        "            # Uncorrelated case (delta function correlation)\n",
        "            C2 = calculate_correlation_matrix(x_2point[:N+1], 1)\n",
        "            t_star, alpha_eff = correlation_fun.calculate_chi_with_background_corrected(\n",
        "                T2_2point[:N+1], alpha_2point[:N+1], N, C2, 9999999, 2)\n",
        "            T2_uncorr.append(t_star)\n",
        "            alpha_uncorr.append(alpha_eff)\n",
        "    \n",
        "    # Save results to fig4 directory (where plotting notebook expects it)\n",
        "    save_path = processed_data_path / 'fig4' / f\"spatial_fit_{field}.pkl\"\n",
        "    with open(save_path, \"wb\") as f:\n",
        "        pickle.dump({\n",
        "            \"alpha_est\": alpha_est,\n",
        "            \"T2_est\": T2_est,\n",
        "            \"x_est\": x_est,\n",
        "            \"alpha_uncorr\": alpha_uncorr,\n",
        "            \"T2_uncorr\": T2_uncorr\n",
        "        }, f)\n",
        "    print(f\"✓ Saved spatial fit for {field} field to {save_path}\")\n",
        "\n",
        "print(\"\\nSpatial correlation fit complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
